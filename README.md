# API de Transcripci√≥n de Audio a PDF - Optimizada para Espa√±ol

Una API REST desarrollada en Flask que permite transcribir archivos de audio en espa√±ol y convertirlos a documentos PDF o DOCX utilizando OpenAI Whisper.

## Caracter√≠sticas

- ‚úÖ Transcripci√≥n de audio usando OpenAI Whisper optimizada para espa√±ol
- ‚úÖ Soporte para m√∫ltiples formatos de audio (MP3, WAV, FLAC, M4A, AAC, OGG, WMA, MP4, AVI, MOV, MKV, WEBM)
- ‚úÖ Generaci√≥n de documentos PDF y DOCX
- ‚úÖ Idioma configurado: Espa√±ol üá™üá∏
- ‚úÖ Soporte para archivos de hasta 1GB
- ‚úÖ API REST f√°cil de usar
- ‚úÖ Metadatos incluidos en los documentos generados
- ‚úÖ Manejo de errores robusto

## üìÅ Estructura del Proyecto (Simplificada)

```
transcribeAudio/
‚îú‚îÄ‚îÄ üêç app.py                 # Aplicaci√≥n Flask principal
‚îú‚îÄ‚îÄ üì¶ requirements.txt       # Dependencias de Python
‚îú‚îÄ‚îÄ üåê test_client.html       # Cliente web para transcripciones
‚îú‚îÄ‚îÄ üìñ README.md              # Documentaci√≥n del proyecto
‚îú‚îÄ‚îÄ üöÄ start.bat/.sh          # Scripts de inicio
‚îú‚îÄ‚îÄ üìÅ uploads/               # Archivos temporales (se limpian autom√°ticamente)
‚îú‚îÄ‚îÄ üìÑ outputs/               # PDFs generados (se descargan al usuario)
‚îî‚îÄ‚îÄ üêç venv/                  # Entorno virtual de Python
```

## üéØ Archivos Principales

- **`app.py`**: Aplicaci√≥n principal con la API Flask
- **`test_client.html`**: Interfaz web para usar la API
- **`requirements.txt`**: Lista de dependencias necesarias
- **`start.bat`/`start.sh`**: Scripts para iniciar la aplicaci√≥n f√°cilmente

## Instalaci√≥n

### Prerrequisitos

- Python 3.8 o superior
- pip
- FFmpeg (se instala autom√°ticamente)

### Instalaci√≥n Autom√°tica (Recomendado)

La forma m√°s f√°cil es usar uno de los scripts de inicio que configuran todo autom√°ticamente:

**Para Windows:**

- **setup_and_run.bat** - Para Command Prompt
- **start_api.ps1** - Para PowerShell
- **start_api.sh** - Para Git Bash/WSL

```bash
# Doble clic en cualquiera de estos archivos
setup_and_run.bat      # Command Prompt
start_api.ps1          # PowerShell (requiere Set-ExecutionPolicy RemoteSigned)
start_api.sh          # Git Bash/WSL
```

### Instalaci√≥n Manual

1. **Clonar o descargar el proyecto**

```bash
cd transcribeAudio
```

2. **Crear entorno virtual (recomendado)**

```bash
python -m venv venv
```

3. **Activar entorno virtual**

   - Windows:

   ```bash
   source venv/Scripts/activate
   ```

   - Linux/Mac:

   ```bash
   source venv/bin/activate
   ```

4. **Instalar dependencias**

```bash
pip install -r requirements.txt
```

5. **Instalar FFmpeg** (requerido para procesamiento de audio):

   ```bash
   # En Windows con winget
   winget install --id=Gyan.FFmpeg -e
   ```

   **‚ö†Ô∏è IMPORTANTE**: Despu√©s de instalar FFmpeg, **debe reiniciar el terminal** para que est√© disponible en el PATH.

## Uso

### Iniciar la API

**Opci√≥n 1: Scripts autom√°ticos (Recomendado)**

- Doble clic en `setup_and_run.bat`, `start_api.ps1` o `start_api.sh`

**Opci√≥n 2: Manualmente**

```bash
python app.py
```

La API estar√° disponible en: `http://localhost:5000`

### Endpoints disponibles

#### GET `/`

Informaci√≥n general de la API

```bash
curl http://localhost:5000/
```

#### GET `/health`

Verificar estado de la API

```bash
curl http://localhost:5000/health
```

#### POST `/transcribe`

Transcribir archivo de audio

**Par√°metros:**

- `audio` (archivo): Archivo de audio a transcribir
- `format` (opcional): Formato de salida (`pdf` o `docx`, por defecto `pdf`)

**Ejemplos:**

```bash
# Transcribir a PDF
curl -X POST -F "audio=@mi_audio.mp3" http://localhost:5000/transcribe --output transcripcion.pdf

# Transcribir a DOCX
curl -X POST -F "audio=@mi_audio.wav" -F "format=docx" http://localhost:5000/transcribe --output transcripcion.docx
```

### Usando Python requests

```python
import requests

# Transcribir archivo de audio
with open('mi_audio.mp3', 'rb') as audio_file:
    files = {'audio': audio_file}
    data = {'format': 'pdf'}  # o 'docx'

    response = requests.post('http://localhost:5000/transcribe', files=files, data=data)

    if response.status_code == 200:
        with open('transcripcion.pdf', 'wb') as f:
            f.write(response.content)
        print("Transcripci√≥n completada!")
    else:
        print(f"Error: {response.json()}")
```

### Usando formulario HTML

```html
<!DOCTYPE html>
<html>
  <head>
    <title>Transcripci√≥n de Audio</title>
  </head>
  <body>
    <h1>Transcribir Audio a PDF</h1>
    <form
      action="http://localhost:5000/transcribe"
      method="post"
      enctype="multipart/form-data"
    >
      <label for="audio">Seleccionar archivo de audio:</label><br />
      <input
        type="file"
        id="audio"
        name="audio"
        accept="audio/*,video/*"
        required
      /><br /><br />

      <label for="format">Formato de salida:</label><br />
      <select id="format" name="format">
        <option value="pdf">PDF</option>
        <option value="docx">DOCX</option></select
      ><br /><br />

      <input type="submit" value="Transcribir" />
    </form>
  </body>
</html>
```

## Formatos de Audio Soportados

- **Audio:** MP3, WAV, FLAC, M4A, AAC, OGG, WMA
- **Video:** MP4, AVI, MOV, MKV, WEBM (se extrae el audio)

## Configuraci√≥n

### Modelo Whisper

Por defecto se usa el modelo `base`. Puedes cambiar a otros modelos editando la l√≠nea en `app.py`:

```python
model = whisper.load_model("base")  # Opciones: tiny, base, small, medium, large
```

**Modelos disponibles:**

- `tiny`: M√°s r√°pido, menos preciso (~39 MB)
- `base`: Balance entre velocidad y precisi√≥n (~74 MB)
- `small`: Mejor precisi√≥n, m√°s lento (~244 MB)
- `medium`: Excelente precisi√≥n, considerablemente m√°s lento (~769 MB) ‚≠ê **ACTUAL**
- `large`: M√°xima precisi√≥n, muy lento (~1550 MB)

## üöÄ Despliegue en Render

### Gu√≠a Paso a Paso para Render

#### 1. **Preparar Repositorio en GitHub**

```bash
# 1. Sube tu c√≥digo a GitHub
git init
git add .
git commit -m "API de transcripci√≥n lista para Render"
git branch -M main
git remote add origin https://github.com/tu-usuario/transcribe-audio-api.git
git push -u origin main
```

#### 2. **Configurar en Render**

1. Ve a [render.com](https://render.com) y crea una cuenta
2. Haz clic en "New +" ‚Üí "Web Service"
3. Conecta tu repositorio de GitHub
4. Configura los siguientes valores:

**Configuraci√≥n de Build & Deploy:**

- **Name**: `transcribe-audio-api`
- **Environment**: `Python 3`
- **Build Command**: `pip install -r requirements.txt`
- **Start Command**: `python app.py`
- **Instance Type**: `Standard` (recomendado para modelo medium)

#### 3. **Variables de Entorno en Render**

En la secci√≥n "Environment Variables" de Render, agrega:

```bash
FLASK_ENV=production
PORT=10000
PYTHON_VERSION=3.9.18
```

#### 4. **Configuraci√≥n Avanzada**

- **Auto-Deploy**: `Yes` (para actualizaciones autom√°ticas)
- **Health Check Path**: `/health`
- **Region**: `Oregon` (recomendado para latencia)

### ‚ö†Ô∏è Consideraciones Importantes para Render

**Plan Gratuito:**

- ‚úÖ 750 horas gratis por mes
- ‚ö†Ô∏è Se suspende despu√©s de 15 min de inactividad (cold start)
- ‚ö†Ô∏è Primera carga del modelo Whisper puede tomar 5-10 minutos

**Plan Standard ($7/mes) - Recomendado para producci√≥n:**

- ‚úÖ Sin suspensi√≥n autom√°tica
- ‚úÖ Mejor rendimiento
- ‚úÖ SSL autom√°tico

### üîß Soluci√≥n de Problemas en Render

**Build Time Out:**

```bash
# Si el build toma m√°s de 15 minutos, considera cambiar a modelo 'small'
# En app.py l√≠nea 87, cambiar:
model = whisper.load_model("small")  # En lugar de "medium"
```

**Memory Issues:**

```bash
# Upgrade a Standard plan o usar modelo m√°s peque√±o
```

**URL de tu API despu√©s del deploy:**

```
https://tu-servicio-nombre.onrender.com
```

## Estructura del Proyecto

```
transcribeAudio/
‚îú‚îÄ‚îÄ app.py              # Aplicaci√≥n principal
‚îú‚îÄ‚îÄ requirements.txt    # Dependencias
‚îú‚îÄ‚îÄ README.md          # Este archivo
‚îú‚îÄ‚îÄ uploads/           # Archivos temporales (se crea autom√°ticamente)
‚îî‚îÄ‚îÄ outputs/           # Archivos generados (se crea autom√°ticamente)
```

## Respuestas de la API

### √âxito (200)

Retorna el archivo PDF o DOCX directamente como descarga.

### Errores

**400 - Bad Request**

```json
{
  "error": "Descripci√≥n del error"
}
```

**413 - Payload Too Large**

```json
{
  "error": "Archivo demasiado grande. M√°ximo permitido: 1GB"
}
```

**500 - Internal Server Error**

```json
{
  "error": "Error interno del servidor: descripci√≥n"
}
```

## Caracter√≠sticas del Documento Generado

Los documentos PDF y DOCX incluyen:

- T√≠tulo: "Transcripci√≥n de Audio"
- Metadatos:
  - Fecha y hora de transcripci√≥n
  - Nombre del archivo original
  - Duraci√≥n del audio (cuando est√° disponible)
- Texto transcrito formateado en p√°rrafos

## Rendimiento y Consideraciones

- **Primera ejecuci√≥n:** Puede tardar m√°s tiempo debido a la descarga del modelo Whisper
- **Archivos grandes:** La transcripci√≥n puede tomar varios minutos dependiendo del tama√±o
- **Memoria:** El modelo base requiere aproximadamente 1GB de RAM
- **CPU vs GPU:** Whisper puede usar GPU para acelerar la transcripci√≥n si est√° disponible

## Soluci√≥n de Problemas

### Error: "No module named 'whisper'"

```bash
pip install openai-whisper
```

### Error: "torch not found"

```bash
pip install torch torchvision torchaudio
```

### Error de memoria

- Usar un modelo m√°s peque√±o (`tiny` en lugar de `base`)
- Procesar archivos m√°s peque√±os
- Aumentar la memoria del sistema

### El audio no se transcribe

- Verificar que el archivo contenga speech
- Verificar el formato del archivo
- Probar con otro archivo de audio

## Desarrollo

Para contribuir al proyecto:

1. Fork el repositorio
2. Crear una rama para tu feature: `git checkout -b feature/nueva-caracteristica`
3. Commit tus cambios: `git commit -am 'Agregar nueva caracter√≠stica'`
4. Push a la rama: `git push origin feature/nueva-caracteristica`
5. Crear un Pull Request

## Licencia

Este proyecto est√° bajo la Licencia MIT.

## Soporte

Para reportar bugs o solicitar features, por favor crear un issue en el repositorio del proyecto.
